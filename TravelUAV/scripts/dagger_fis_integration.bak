import os
import sys
import torch
import numpy as np
from pathlib import Path

ROOT = Path(__file__).resolve().parents[2]
sys.path.append(str(ROOT / "Fast-in-Slow"))
sys.path.append(str(ROOT / "TravelUAV"))

from models.load import load_vla
from models.vlas.fisvla import FiSvla
from src.vlnce_src.env_uav import AirVLNENV
from util.uav_data_integration import DAggerDataAggregator
from util.uav_data_utils import UAVDataProcessor


class FiSTravelUAVDagger:
    """FiS与TravelUAV的DAgger集成训练"""
    
    def __init__(self, config):
        self.config = config
        # 初始化环境，复用现有环境构造签名
        self.uav_env = AirVLNENV(
            batch_size=getattr(config, 'batch_size', 4),
            dataset_path=getattr(config, 'dataset_path', None),
            save_path=getattr(config, 'dagger_save_path', None),
            eval_json_path=getattr(config, 'eval_json_path', None),
            seed=getattr(config, 'seed', 1),
            dataset_group_by_scene=getattr(config, 'dataset_group_by_scene', True),
            activate_maps=getattr(config, 'activate_maps', []),
        )
        self.uav_processor = UAVDataProcessor()
        
        # 加载FiS模型
        self.fis_model = self.load_fis_model(getattr(config, 'model_path', None))
        self.fis_model.eval()
        
        # DAgger数据聚合器
        self.aggregator = DAggerDataAggregator(max_dataset_size=getattr(config, 'max_dataset_size', 100000),
                                               expert_data_ratio=getattr(config, 'expert_data_ratio', 0.3))
    
    def load_fis_model(self, model_path):
        """加载预训练的FiS模型
        支持两种路径：
        - 运行目录（包含`config.json`与`checkpoints/latest-checkpoint.pt`）
        - 直接checkpoint路径（`runs/<id>/checkpoints/step-...pt`）
        """
        assert model_path is not None, "model_path 未提供"
        path = Path(model_path)
        if path.is_dir():
            # 运行目录：选择latest-checkpoint
            ckpt = path / "checkpoints" / "latest-checkpoint.pt"
            assert ckpt.exists(), f"未找到checkpoint: {ckpt}"
            return load_vla(ckpt,
                            load_for_training=False,
                            use_diff=getattr(self.config, 'use_diff', False),
                            action_chunk=getattr(self.config, 'action_chunk', 1),
                            load_pointcloud=getattr(self.config, 'load_pointcloud', False),
                            pointcloud_pos=getattr(self.config, 'pointcloud_pos', 'slow'),
                            load_state=getattr(self.config, 'load_state', True),
                            )
        else:
            # 直接checkpoint文件
            assert path.exists(), f"checkpoint 文件不存在: {path}"
            return load_vla(path,
                            load_for_training=False,
                            use_diff=getattr(self.config, 'use_diff', False),
                            action_chunk=getattr(self.config, 'action_chunk', 1),
                            load_pointcloud=getattr(self.config, 'load_pointcloud', False),
                            pointcloud_pos=getattr(self.config, 'pointcloud_pos', 'slow'),
                            load_state=getattr(self.config, 'load_state', True),
                            )
    
    def run_dagger_iteration(self, iteration):
        """运行一次DAgger迭代"""
        print(f"Starting DAgger iteration {iteration}")
        
        # 1. 使用当前模型收集轨迹
        collected_data = self.collect_trajectories()
        
        # 2. 专家标注（回溯机制）
        expert_data = self.get_expert_corrections(collected_data)
        
        # 3. 数据聚合
        aggregated_data = self.aggregate_data(collected_data, expert_data)
        
        # 4. 重新训练模型（占位：将数据保存到磁盘并由现有脚本训练）
        self.retrain_model(aggregated_data)
        
        print(f"Completed DAgger iteration {iteration}")
    
    def collect_trajectories(self):
        """使用当前FiS模型收集UAV轨迹，按batch遍历环境数据，闭环采集"""
        episodes_collected = []
        
        # 获取一个batch并重置环境
        env_batch = self.uav_env.next_minibatch(skip_scenes=[])
        if env_batch is None:
            return episodes_collected
        
        obs_list = self.uav_env.reset()  # List[observations]
        
        # 建立每个并行环境的episode容器
        batch_size = len(obs_list)
        for i in range(batch_size):
            episodes_collected.append([])
        
        for t in range(int(getattr(self.config, 'max_steps', 200))):
            # 处理观测数据并预测
            refined_waypoints = []
            for i, obs in enumerate(obs_list):
                # obs 是 observations 列表，最后一个元素含丰富键
                last_obs = obs[-1]
                processed = self.process_observation(last_obs)
                
                # FiS预测，支持 pointcloud + instruction + state
                with torch.no_grad():
                    pred = self.fis_model.predict_action(
                        point_cloud=processed.get('pointcloud'),
                        instruction=processed.get('instruction', ''),
                        cur_robot_state=processed.get('proprio'),
                        predict_mode=getattr(self.config, 'predict_mode', 'diff'),
                    )
                
                # 将动作映射为5步航点：按速度/位移近似生成或直接用teacher作为回退
                # FiS可能返回不同模式；这里统一为 np.ndarray 形状 [1, action_dim]
                if isinstance(pred, tuple):
                    # diff+ar 或 ar 返回 (actions, subgoals)
                    if len(pred) == 3:  # diff+ar
                        actions = pred[0]
                    elif len(pred) == 2:  # ar
                        actions = pred[0]
                    else:
                        actions = pred
                else:
                    actions = pred
                
                if actions is None:
                    # 回退：使用教师航点
                    wp = last_obs.get('teacher_action', [[0,0,0]]*5)
                    refined_waypoints.append(wp)
                else:
                    act = np.array(actions).reshape(-1)
                    # 将 6-DoF action 近似为位移增量，生成 5 步
                    # 假设 act[:3] 速度或位移，单位步长1米；从当前位姿生成
                    cur_pos = np.array(self.uav_env.sim_states[i].pose[0:3])
                    delta = act[:3]
                    if np.linalg.norm(delta) < 1e-6 and 'teacher_action' in last_obs:
                        wp = last_obs['teacher_action']
                    else:
                        step = max(1.0, getattr(self.config, 'waypoint_step', 1.0))
                        wp = [ (cur_pos + (k+1) * step * delta).tolist() for k in range(5) ]
                    refined_waypoints.append(wp)
                
                # 记录步骤数据
                episodes_collected[i].append({
                    'observation': last_obs,
                    'processed': processed,
                    'pred_actions': actions if actions is not None else None,
                    'refined_waypoints': refined_waypoints[-1],
                })
            
            # 驱动环境执行动作（批处理）
            self.uav_env.makeActions(refined_waypoints)
            obs_list = self.uav_env.get_obs()
        
        return episodes_collected
    
    def process_observation(self, obs):
        """处理TravelUAV观测数据为FiS格式
        预期obs为VectorEnvUtil._format_obs_at返回的observations[-1]
        键包括：'rgb', 'depth', 'sensor'/'sensors'中的'state'，'instruction', 'teacher_action'
        """
        processed = {}
        
        # RGB图像
        if 'rgb' in obs:
            processed['pixel_values'] = self.uav_processor._process_rgb_images(obs['rgb'])
        
        # 深度 -> 点云
        if 'depth' in obs:
            processed['pointcloud'] = self.uav_processor._process_depth_to_pointcloud(
                obs['depth'], obs.get('rgb', None)
            )
        
        # UAV状态（兼容sensor/sensors键）
        sensor_obj = obs.get('sensor') or obs.get('sensors')
        if sensor_obj and 'state' in sensor_obj:
            uav_state_np = self.uav_processor.process_uav_state(sensor_obj['state'])
            processed['proprio'] = torch.tensor(uav_state_np).float().unsqueeze(0)
        
        # 指令
        if 'instruction' in obs:
            processed['instruction'] = obs['instruction']
        
        # 教师航点（用于监督或回退）
        if 'teacher_action' in obs:
            processed['teacher_action'] = obs['teacher_action']
        
        return processed
    
    def get_expert_corrections(self, collected_data):
        """提取专家纠正数据：直接使用观测中的'teacher_action'"""
        expert_items = []
        for episode in collected_data:
            for step in episode:
                obs = step['observation']
                if 'teacher_action' in obs and obs['teacher_action'] is not None:
                    expert_items.append({
                        'observation': obs,
                        'teacher_action': obs['teacher_action'],
                    })
        return expert_items
    
    def aggregate_data(self, collected_data, expert_data):
        """聚合收集的数据与专家数据到聚合器"""
        # 模型数据：为每步记录构造简化样本
        model_items = []
        for episode in collected_data:
            for step in episode:
                item = {
                    'observation': step['observation'],
                    'processed': step.get('processed'),
                    'pred_actions': step.get('pred_actions'),
                    'refined_waypoints': step.get('refined_waypoints'),
                }
                model_items.append(item)
        
        self.aggregator.add_model_data(model_items)
        self.aggregator.add_expert_data(expert_data)
        
        # 可选：保存到磁盘
        save_path = Path(getattr(self.config, 'dagger_save_path', './data/dagger_fis_uav'))
        save_path.mkdir(parents=True, exist_ok=True)
        # 在保存前，将teacher_action转换为6-DoF动作
        for item in expert_data:
            item['teacher_action'] = self.uav_processor.process_teacher_action(
                item['teacher_action'], item['observation']['sensors']['state']
            )
        self.aggregator.save_dataset(save_path)
        
        return self.aggregator.get_aggregated_dataset()
    
    def retrain_model(self, aggregated_data):
        """占位：保存聚合数据并提供训练入口参数
        实际训练复用 Fast-in-Slow/scripts/train.py，通过外部脚本读取RLDS或UAV数据。
        这里仅记录数据规模与推荐命令。
        """
        print(f"Aggregated dataset size: {len(aggregated_data)}")
        print("建议使用以下命令进行再训练：")
        print("torchrun --standalone --nproc-per-node 1 Fast-in-Slow/scripts/train.py --use_uav_dataset True --load_pointcloud True --action_dim 6 --future_action_window_size 15")


if __name__ == "__main__":
    # 配置参数
    class Config:
        batch_size = 4
        episodes_per_iteration = 10
        max_steps = 50
        dagger_iterations = 1
        model_path = str(ROOT / "Fast-in-Slow" / "runs" / "EXP_FiSvla_OXE_MAGIC_SOUP_PLUS_MINUS+n1+b8+x42" )
        dagger_save_path = str(ROOT / "TravelUAV" / "data" / "dagger_fis_uav")
        dataset_path = getattr(__import__('src.common.param', fromlist=['args']).args, 'dataset_path', None)
        eval_json_path = getattr(__import__('src.common.param', fromlist=['args']).args, 'train_json_path', None)
        seed = 1
        dataset_group_by_scene = True
        activate_maps = []
        use_diff = False
        load_pointcloud = False
        pointcloud_pos = 'slow'
        load_state = True
        predict_mode = 'diff'
        action_chunk = 1
        max_dataset_size = 100000
        expert_data_ratio = 0.3
        waypoint_step = 1.0
    
    config = Config()
    dagger_trainer = FiSTravelUAVDagger(config)
    
    # 运行DAgger训练
    for iteration in range(config.dagger_iterations):
        dagger_trainer.run_dagger_iteration(iteration)